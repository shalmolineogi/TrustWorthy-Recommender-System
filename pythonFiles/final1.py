# -*- coding: utf-8 -*-
"""Final1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O7Y4X_22fKZLnEPgYcLhhUdA4IyLdIUR
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

books = pd.read_csv('D:\Programs\RecommenderSystem\csvFiles\BX-Books.csv',sep=';',error_bad_lines=False, encoding="latin-1")
books.columns = ['ISBN','bookTitle','bookAuthor','yearOfPublication','publisher','imageUrlS','imageUrlM','imageUrlL']
users = pd.read_csv('D:\Programs\RecommenderSystem\csvFiles\BX-Users.csv',sep=';',error_bad_lines=False, encoding="latin-1")
users.columns = ['userID','Location','Age']
ratings = pd.read_csv('D:\Programs\RecommenderSystem\csvFiles\BX-Book-Ratings.csv',sep=';',error_bad_lines=False, encoding="latin-1")
ratings.columns = ['userID','ISBN','bookRating']

"""# New Section"""

print(books.shape
,users.shape
,ratings.shape)


books.head(100)
ratings

print(ratings.shape)
print(list(ratings.columns))

users.head(10)

ratings.head()

plt.rc("font",size=15)
new_rating = ratings.bookRating.value_counts(sort=False)
print(new_rating, type(new_rating))
new_rating.plot(kind='bar')
plt.title('Rating Distribution\n')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()

#statistical filtering
#books which has <200 users excluded
#books which have <100 rating excluded
c1 = ratings['userID'].value_counts()
print(len(c1))
ratings = ratings[ratings['userID'].isin(c1[c1>=200].index)]
c2 = ratings['bookRating'].value_counts()
ratings = ratings[ratings['bookRating'].isin(c2[c2>=100].index)]
ratings.shape

#combining rating dataset with book dataset on ISBN field
combine_book_rating = pd.merge(ratings, books, on='ISBN')
combine_book_rating = combine_book_rating.drop(['bookAuthor','yearOfPublication','publisher','imageUrlS','imageUrlM','imageUrlL'], axis=1)
print(combine_book_rating.shape)
combine_book_rating.head()

combine_book_rating = combine_book_rating.dropna(axis=0, subset = ['bookTitle'])
book_ratingCount = (combine_book_rating.groupby(by=['bookTitle'])['bookRating'].count().reset_index().rename(columns = { 'bookRating':'totalRatingCount'})[['bookTitle','totalRatingCount']])
book_ratingCount.head()
book_ratingCount.shape

rating_with_totalRatingCount = combine_book_rating.merge(book_ratingCount, left_on = 'bookTitle', right_on = 'bookTitle', how = 'left' )
rating_with_totalRatingCount.shape

#giving some popularity thresold to discard less popular books
popularity_thresold = 50
rating_popular_book = rating_with_totalRatingCount.query('totalRatingCount >= @popularity_thresold')
rating_popular_book.head()
rating_popular_book.shape

rating_popular_book.shape

##toomany records..

users.head(10)

#lets take only books which has users of usa and canada
# combined = rating_popular_book.merge(users,left_on='userID',right_on='userID',how='left')
# us_canada_user_rating = combined[combined['Location'].str.contains("usa|canada")]
# us_canada_user_rating = us_canada_user_rating.drop('Age',axis=1)
# us_canada_user_rating.head()

us_canada_user_rating = rating_popular_book.merge(users,left_on='userID',right_on='userID',how='left')
us_canada_user_rating.shape
# us_canada_user_rating = combined[combined['Location'].str.contains("usa|canada")]
us_canada_user_rating = us_canada_user_rating.drop('Age',axis=1)
us_canada_user_rating.head()
us_canada_user_rating.shape

us_canada_user_rating.shape

#knn implementation
#initial requirements satisfying
from scipy.sparse import csr_matrix
import math
us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID','bookTitle'])
us_canada_user_rating_pivot = us_canada_user_rating.pivot(index='userID', columns = 'bookTitle', values = 'bookRating')
us_canada_user_rating_matrix = csr_matrix(us_canada_user_rating_pivot.values)
bookTitle = us_canada_user_rating_pivot.columns
userID = us_canada_user_rating_pivot.index
#print(bookTitle[0])
#print(userID[0])
# books0 = np.array(us_canada_user_rating_pivot.xs((userID[0])))
# books1 = np.array(us_canada_user_rating_pivot.xs((userID[1])))
# #print(books0)
# #print(books1)
# ratDiff = 1-(np.absolute(books0-books1))/10

# print(ratDiff)
# sum(ratDiff)/746
# #print(len(books))
#print(books[0]-books[1])
#us_canada_user_rating_pivot.head()

us_canada_user_rating_pivot

n,m = us_canada_user_rating_pivot.shape
print(n,m)
a = np.zeros((n,n))
for i in range(len(userID)):
    print("i :"+str(i))
    a[i][i]=1
    trust=0
    bookRatingsI =  us_canada_user_rating_pivot.xs((userID[i]))
    for j in range(i+1,len(userID)):
        bookRatingsJ =  us_canada_user_rating_pivot.xs((userID[j]))
        d = 1 - (abs(bookRatingsI-bookRatingsJ))/10
        d = d.dropna()
        if (len(d)!= 0):
            trust = sum(d) / len(d)
        a[i][j] = trust
        a[j][i] = trust
        trust = 0
        
print(a)

'''plt.rc("font",size=15)
us_canada_user_rating_pivot.bookRating.value_counts(sort=False).plot(kind='bar')
plt.title('Rating Distribution\n')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()'''
#%matplotlib inline
#us_canada_user_rating_pivot.plot.bar()
#plt.show()

#implementing knn
from sklearn.neighbors import NearestNeighbors
model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
model_knn.fit(us_canada_user_rating_matrix)

us_canada_user_rating_pivot.iloc[query_index,:].values.reshape(1,-1)

query_index = np.random.choice(us_canada_user_rating_pivot.shape[1])
print(query_index)
a=us_canada_user_rating_pivot.iloc[:,query_index]
print(us_canada_user_rating_pivot.iloc[:,query_index])
print(a.shape)
distances, indices = model_knn.kneighbors(us_canada_user_rating_pivot.iloc[:,query_index].values.reshape(1,0), n_neighbors=6)
print(distances)
print(indices)

us_canada_user_rating_pivot.index[query_index]

for i in range(0, len(distances.flatten())):
    if i==0:
        print('Recommendations for {0}:\n'.format(us_canada_user_rating_pivot.index[query_index]))
    else:
        print('{0}: {1}, with distance of {2}:'.format(i,us_canada_user_rating_pivot.index[indices.flatten()[i]], distances.flatten()[i]))

## lesser the distance more the similarity